{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  本部分主要对维基百科的信息的进行抽取和繁体的转换操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanziconv import HanziConv\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from gensim.corpora import WikiCorpus\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 articles\n",
      "Processed 100000 articles\n",
      "Processed 200000 articles\n",
      "Processed 300000 articles\n",
      "Processed 400000 articles\n",
      "Processed 500000 articles\n",
      "Processed 600000 articles\n",
      "Processed 700000 articles\n",
      "Processed 800000 articles\n",
      "Processed 900000 articles\n",
      "Processed 1000000 articles\n",
      "Processed 1100000 articles\n",
      "Processed 1200000 articles\n",
      "Processed 1300000 articles\n",
      "Processed 1400000 articles\n",
      "Processed 1500000 articles\n",
      "Processed 1600000 articles\n",
      "Processed 1700000 articles\n",
      "Processed 1800000 articles\n",
      "Processed 1900000 articles\n",
      "Processed 2000000 articles\n",
      "Processed 2100000 articles\n",
      "Processed 2200000 articles\n",
      "Processed 2300000 articles\n",
      "Processed 2400000 articles\n",
      "Processed 2500000 articles\n",
      "Processed 2600000 articles\n",
      "Processed 2700000 articles\n",
      "Processed 2800000 articles\n",
      "Processed 2900000 articles\n",
      "Processed 3000000 articles\n",
      "Processed 3100000 articles\n",
      "Processed 3200000 articles\n",
      "Processed 3300000 articles\n",
      "Processed 3400000 articles\n",
      "Processed 3500000 articles\n",
      "Processed 3600000 articles\n",
      "Processed 3700000 articles\n",
      "Processed 3800000 articles\n",
      "Processed 3900000 articles\n",
      "Processed 4000000 articles\n",
      "Processed 4100000 articles\n",
      "Processed 4200000 articles\n",
      "Processed 4300000 articles\n",
      "Processed 4400000 articles\n",
      "Processed 4500000 articles\n",
      "Processed 4600000 articles\n",
      "Processed 4700000 articles\n",
      "Processed 4800000 articles\n",
      "Processed 4900000 articles\n",
      "wiki_00 has been processed !\n",
      "Processed 0 articles\n",
      "Processed 100000 articles\n",
      "Processed 200000 articles\n",
      "Processed 300000 articles\n",
      "Processed 400000 articles\n",
      "Processed 500000 articles\n",
      "Processed 600000 articles\n",
      "Processed 700000 articles\n",
      "Processed 800000 articles\n",
      "Processed 900000 articles\n",
      "Processed 1000000 articles\n",
      "Processed 1100000 articles\n",
      "Processed 1200000 articles\n",
      "Processed 1300000 articles\n",
      "Processed 1400000 articles\n",
      "Processed 1500000 articles\n",
      "Processed 1600000 articles\n",
      "Processed 1700000 articles\n",
      "Processed 1800000 articles\n",
      "Processed 1900000 articles\n",
      "Processed 2000000 articles\n",
      "Processed 2100000 articles\n",
      "Processed 2200000 articles\n",
      "Processed 2300000 articles\n",
      "Processed 2400000 articles\n",
      "Processed 2500000 articles\n",
      "Processed 2600000 articles\n",
      "Processed 2700000 articles\n",
      "Processed 2800000 articles\n",
      "Processed 2900000 articles\n",
      "Processed 3000000 articles\n",
      "Processed 3100000 articles\n",
      "Processed 3200000 articles\n",
      "Processed 3300000 articles\n",
      "Processed 3400000 articles\n",
      "Processed 3500000 articles\n",
      "Processed 3600000 articles\n",
      "Processed 3700000 articles\n",
      "Processed 3800000 articles\n",
      "Processed 3900000 articles\n",
      "Processed 4000000 articles\n",
      "Processed 4100000 articles\n",
      "Processed 4200000 articles\n",
      "Processed 4300000 articles\n",
      "Processed 4400000 articles\n",
      "Processed 4500000 articles\n",
      "Processed 4600000 articles\n",
      "Processed 4700000 articles\n",
      "Processed 4800000 articles\n",
      "Processed 4900000 articles\n",
      "Processed 5000000 articles\n",
      "Processed 5100000 articles\n",
      "Processed 5200000 articles\n",
      "Processed 5300000 articles\n",
      "Processed 5400000 articles\n",
      "Processed 5500000 articles\n",
      "Processed 5600000 articles\n",
      "Processed 5700000 articles\n",
      "Processed 5800000 articles\n",
      "Processed 5900000 articles\n",
      "Processed 6000000 articles\n",
      "Processed 6100000 articles\n",
      "Processed 6200000 articles\n",
      "Processed 6300000 articles\n",
      "Processed 6400000 articles\n",
      "Processed 6500000 articles\n",
      "Processed 6600000 articles\n",
      "Processed 6700000 articles\n",
      "Processed 6800000 articles\n",
      "Processed 6900000 articles\n",
      "Processed 7000000 articles\n",
      "Processed 7100000 articles\n",
      "wiki_01 has been processed !\n",
      "Processed 0 articles\n",
      "Processed 100000 articles\n",
      "Processed 200000 articles\n",
      "Processed 300000 articles\n",
      "Processed 400000 articles\n",
      "Processed 500000 articles\n",
      "Processed 600000 articles\n",
      "Processed 700000 articles\n",
      "Processed 800000 articles\n",
      "Processed 900000 articles\n",
      "Processed 1000000 articles\n",
      "wiki_02 has been processed !\n"
     ]
    }
   ],
   "source": [
    "def replace_func(input_file):\n",
    "    p1 = re.compile('（）')\n",
    "    p2 = re.compile('《》')\n",
    "    p3 = re.compile('「')\n",
    "    p4 = re.compile('」')\n",
    "    p5 = re.compile('<doc (.*)>')\n",
    "    p6 = re.compile('</doc>')\n",
    "    outfile = codecs.open(r'./wiki_zh_simple.txt', 'w', 'utf-8')\n",
    "    with codecs.open(input_file, 'r', 'utf-8') as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "            if i % 100000 == 0:\n",
    "                print('Processed ' + str(i) + \" articles\")\n",
    "            line = p1.sub('', line)\n",
    "            line = p2.sub('', line)\n",
    "            line = p3.sub('', line)\n",
    "            line = p4.sub('', line)\n",
    "            line = p5.sub('', line)\n",
    "            line = p6.sub('', line)\n",
    "            line = HanziConv.toSimplified(line)   # 转化为简体\n",
    "            #print(line)\n",
    "            outfile.write(line)\n",
    "    outfile.close()\n",
    "\n",
    "def run():\n",
    "    data_path = r'./wiki_extracted/AA/'\n",
    "    data_names = ['wiki_00', 'wiki_01', 'wiki_02']\n",
    "    for data_name in data_names:\n",
    "        replace_func(data_path + data_name)\n",
    "        print('{0} has been processed !'.format(data_name))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "WikiCorpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
